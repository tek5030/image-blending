{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Welcome to the Image Blending lab!\n","\n","Let's just warm up, declaring a very simple function.\n","\n","We can call the function with a name as an argument, or leave it blank to get the default value\n","```py\n","hello(\"student\")\n","hello()\n","```\n","\n","Let's try. Go to the section below, and press `Shift + Enter`. It will define the function, and call it. If you want, you can edit the contents of the block and run it again.\n","\n","The output should be printed below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def hello(who=\"world\"):\n","    print(f\"Hello, {who}!\")\n","\n","hello()\n","hello(\"student\")"]},{"cell_type":"markdown","metadata":{},"source":["Wow, that was easy. Now we can begin with the lab.\n","\n","## Image Blending\n","\n","First, we must import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.rcParams['figure.figsize'] = [10, 10]"]},{"cell_type":"markdown","metadata":{},"source":["After we have done this, we can continue with more code, the `import` from the previous block is still valid.\n","\n","For convenience, we define a function for displaying an image in the notebook before we get to work:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def showResultOpenCV(title, img):\n","        cv2.namedWindow(title, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)\n","        cv2.imshow(title, img)\n","        cv2.waitKey(0)\n","\n","def showResult(title, img):\n","        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        plt.title(title)\n","        plt.show()\n","\n","def showResultsSideBySide(title1, img1, title2, img2):\n","        # Display the original and the transformed image\n","        axes = plt.subplots(1, 2)[1]\n","        ax1, ax2 = axes\n","        ax1.set_title(title1)\n","        ax2.set_title(title2)\n","        ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n","        ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n","        plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["First we load an image, and the convert it to a floating point datatype. We also divide it by `255`, the maximum pixel value for a channel. That way, we get an image with pixel intensities between 0 and 1."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_01_fname = \"../../tiger.png\"\n","img_01 = cv2.imread(img_01_fname, cv2.IMREAD_UNCHANGED)\n","img_01 = np.float32(img_01)*(1.0/255.0)\n"]},{"cell_type":"markdown","metadata":{},"source":["After you have managed to load the image successfully, let's take a look at that tiger 🐅"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["showResult(img_01_fname, img_01)"]},{"cell_type":"markdown","metadata":{},"source":["Whoa! 🐯\n","\n","Load one more image and take a look at it:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_02_fname = \"../../white_tiger.png\"\n","img_02 = cv2.imread(img_02_fname, cv2.IMREAD_UNCHANGED)\n","img_02 = np.float32(img_02)*(1.0/255.0)\n","\n","showResult(img_02_fname, img_02)"]},{"cell_type":"markdown","metadata":{},"source":["We will now do a \"dumb\" blending, by just adding the two images together.\n","\n","Since pixel values must be between 0 and 1, we divide the sum by 2, which is the theoretical maximum sum of two pixels."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dumbBlend(img1, img2):\n","        return (img1 + img2)/2.\n","\n","dumb_blend = dumbBlend(img_01, img_02)\n","showResult('dumb_blend', dumb_blend)"]},{"cell_type":"markdown","metadata":{},"source":["Wow, that looks really dumb! 😅\n","\n","We want the left half of the result to be `tiger`, and the right half to be `white_tiger`, so we need a way to control _where_ and _how much_ each image contribute to the final result.\n","We can achieve this if we multiply each image with a mask before adding them together.\n","\n","For the `tiger`, we want max contribution to the left and none to the right, so we create a mask where all pixels on the left half are 1, and the right side are 0.\n","For the `white_tiger`, we want the opposite and can use the inverted mask.\n","\n","We call the mask `weights`, since we in practice compute a weighted sum of images."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def linearBlend(img1, img2, weights):\n","        return np.multiply(img1, weights) + np.multiply(img2, 1.-weights)\n","\n","# The weight image is the same size as the input image\n","weights = np.zeros(img_01.shape, dtype=np.float32)\n","half_image_width = int(weights.shape[1]/2)\n","\n","# In the left half of the image, we set all pixels to {1,1,1}\n","weights[:, :half_image_width] = (1., 1., 1.)\n","\n","linear_blend = linearBlend(img_01, img_02, weights)\n","showResultsSideBySide('weights', weights, 'linear_blend', linear_blend)\n"]},{"cell_type":"markdown","metadata":{},"source":["So far, so good, but to call this a \"blend\" would be an overstatement. Let's blur the transition between 0 and 1!\n","\n","Feel free to experiment with the ramp width."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ramp_width = 150\n","blurred_weights = cv2.blur(weights, (ramp_width+1, ramp_width+1))\n","\n","linear_blend = linearBlend(img_01, img_02, blurred_weights)\n","\n","showResult('linear_blend', linear_blend)"]},{"cell_type":"markdown","metadata":{},"source":["Well, we're getting there, but we can do better.\n","\n","We are going to use Laplace blending, as you have learned in this week's lecture."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gaussPyr(img):\n","    pyr = [img]\n","    while pyr[-1].shape[1] > 16:\n","        pyr.append(cv2.pyrDown(pyr[-1]))\n","    return pyr\n","\n","def laplacePyr(img):\n","    pyr = gaussPyr(img)\n","    for i in range(len(pyr)-1):\n","        pyr[i] = pyr[i] - cv2.pyrUp(pyr[i+1],dstsize=pyr[i].shape[0:2])\n","    return pyr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pyr_mask = gaussPyr(weights)\n","pyr_img1 = laplacePyr(img_01)\n","pyr_img2 = laplacePyr(img_02)\n","pyr_blend = []\n","for img1, img2, mask in zip(pyr_img1, pyr_img2, pyr_mask):\n","    pyr_blend.append(\n","        linearBlend(img1, img2, mask)\n","    )\n","\n","def collapsePyr(pyr):\n","    for i, img in reversed(list(enumerate(pyr[:-1]))):\n","        pyr[i] = pyr[i] + cv2.pyrUp(pyr[i+1], dstsize=pyr[i].shape[0:2])\n","    \n","    return pyr[0]\n","\n","blend = collapsePyr(pyr_blend)\n","showResult('blend', blend)"]},{"cell_type":"markdown","metadata":{},"source":["Now that's just beautiful!"]}],"metadata":{"interpreter":{"hash":"ed256a18594ec9b0f55374f879222e6e3e500b3b0e7419e2ae8bbe849e357d3c"},"kernelspec":{"display_name":"Python 3.9.9 64-bit ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
